{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "FILE_PATH = './Dataset/EURUSD/EURUSD_M30_features+label_v.2.1.csv'\n",
    "# Hyperparameters\n",
    "seq_length = 15\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "batch_size = 1024\n",
    "epochs = 50\n",
    "dropout = 0.4\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data = pd.read_csv(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features and labels\n",
    "features = ['Close', 'SMA200', 'SMA50', 'RSI14']\n",
    "label_column = 'signal'\n",
    "data = data[features + [label_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data and round to 4 decimal places\n",
    "scaler = MinMaxScaler()\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "data = data.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle labels\n",
    "data[label_column] = data[label_column].apply(lambda x: int(x) if x in [1, 2, 3] else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = data[features].values\n",
    "y = data[label_column].values - 1  # Adjusting labels for 0-based indexing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model definition\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_layers, seq_length, dropout, num_classes):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, nhead=num_heads, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layer, num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x[:, -1, :])  # Taking the last token's output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data to a pickle file\n",
    "processed_data = {\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train,\n",
    "    'X_test': X_test,\n",
    "    'y_test': y_test\n",
    "}\n",
    "\n",
    "pickle_path = \"./Dataset/EURUSD/EURUSD_M30_features+label_v.2.2.pkl\"\n",
    "with open(pickle_path, 'wb') as file:\n",
    "    pickle.dump(processed_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "input_dim = len(features)\n",
    "num_classes = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = TransformerModel(input_dim, num_heads, num_layers, seq_length, dropout, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 164.1566\n",
      "Epoch 2/50, Loss: 163.0373\n",
      "Epoch 3/50, Loss: 163.0244\n",
      "Epoch 4/50, Loss: 162.9927\n",
      "Epoch 5/50, Loss: 163.0084\n",
      "Epoch 6/50, Loss: 162.9855\n",
      "Epoch 7/50, Loss: 162.9963\n",
      "Epoch 8/50, Loss: 162.9864\n",
      "Epoch 9/50, Loss: 163.0043\n",
      "Epoch 10/50, Loss: 162.9905\n",
      "Epoch 11/50, Loss: 162.9811\n",
      "Epoch 12/50, Loss: 162.9730\n",
      "Epoch 13/50, Loss: 162.9767\n",
      "Epoch 14/50, Loss: 162.9603\n",
      "Epoch 15/50, Loss: 162.9711\n",
      "Epoch 16/50, Loss: 162.9669\n",
      "Epoch 17/50, Loss: 162.9632\n",
      "Epoch 18/50, Loss: 162.9560\n",
      "Epoch 19/50, Loss: 162.9596\n",
      "Epoch 20/50, Loss: 162.9629\n",
      "Epoch 21/50, Loss: 162.9627\n",
      "Epoch 22/50, Loss: 162.9566\n",
      "Epoch 23/50, Loss: 162.9573\n",
      "Epoch 24/50, Loss: 162.9558\n",
      "Epoch 25/50, Loss: 162.9549\n",
      "Epoch 26/50, Loss: 162.9459\n",
      "Epoch 27/50, Loss: 162.9511\n",
      "Epoch 28/50, Loss: 162.9422\n",
      "Epoch 29/50, Loss: 162.9461\n",
      "Epoch 30/50, Loss: 162.9457\n",
      "Epoch 31/50, Loss: 162.9462\n",
      "Epoch 32/50, Loss: 162.9442\n",
      "Epoch 33/50, Loss: 162.9437\n",
      "Epoch 34/50, Loss: 162.9391\n",
      "Epoch 35/50, Loss: 162.9437\n",
      "Epoch 36/50, Loss: 162.9394\n",
      "Epoch 37/50, Loss: 162.9381\n",
      "Epoch 38/50, Loss: 162.9376\n",
      "Epoch 39/50, Loss: 162.9380\n",
      "Epoch 40/50, Loss: 162.9409\n",
      "Epoch 41/50, Loss: 162.9369\n",
      "Epoch 42/50, Loss: 162.9356\n",
      "Epoch 43/50, Loss: 162.9387\n",
      "Epoch 44/50, Loss: 162.9384\n",
      "Epoch 45/50, Loss: 162.9368\n",
      "Epoch 46/50, Loss: 162.9347\n",
      "Epoch 47/50, Loss: 162.9335\n",
      "Epoch 48/50, Loss: 162.9351\n",
      "Epoch 49/50, Loss: 162.9355\n",
      "Epoch 50/50, Loss: 162.9335\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "def train_model(model, X_train, y_train, batch_size, epochs, criterion, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for i in range(0, len(X_train) - seq_length, batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            batch_x = [X_train[j:j+seq_length] for j in range(i, min(i+batch_size, len(X_train)-seq_length))]\n",
    "            batch_y = y_train[i:i+len(batch_x)]\n",
    "            \n",
    "            batch_x = torch.stack(batch_x).to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "train_model(model, X_train, y_train, batch_size, epochs, criterion, optimizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
